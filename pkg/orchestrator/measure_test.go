// Copyright (c) 2026 Petar Djukic. All rights reserved.
// SPDX-License-Identifier: MIT

package orchestrator

import (
	"fmt"
	"testing"
)

func TestValidateMeasureOutput_CodeP9InRange(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Valid code task",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if vr.HasErrors() {
		t.Errorf("expected no errors for valid code task, got: %v", vr.Errors)
	}
}

func TestValidateMeasureOutput_CodeP9TooFewRequirements(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Underconstrained task",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if !vr.HasErrors() {
		t.Error("expected errors for code task with 2 requirements (P9 range 5-8)")
	}
	if len(vr.Errors) != 1 {
		t.Errorf("expected 1 error, got %d: %v", len(vr.Errors), vr.Errors)
	}
}

func TestValidateMeasureOutput_CodeP9TooManyRequirements(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Overconstrained task",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
  - id: R6
    text: req6
  - id: R7
    text: req7
  - id: R8
    text: req8
  - id: R9
    text: req9
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if !vr.HasErrors() {
		t.Error("expected errors for code task with 9 requirements (P9 range 5-8)")
	}
}

func TestValidateMeasureOutput_DocP9InRange(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Valid doc task",
		Description: `deliverable_type: documentation
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if vr.HasErrors() {
		t.Errorf("expected no errors for valid doc task, got: %v", vr.Errors)
	}
}

func TestValidateMeasureOutput_DocP9TooManyRequirements(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Over-specified doc",
		Description: `deliverable_type: documentation
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if !vr.HasErrors() {
		t.Error("expected errors for doc task with 5 requirements (P9 range 2-4)")
	}
}

func TestValidateMeasureOutput_P7ViolationFileNameMatchesPackage(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "P7 violation task",
		Description: `deliverable_type: code
files:
  - path: pkg/testutils/testutils.go
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if !vr.HasErrors() {
		t.Error("expected errors for file named after package (P7 violation)")
	}
	found := false
	for _, e := range vr.Errors {
		if contains(e, "P7 violation") {
			found = true
			break
		}
	}
	if !found {
		t.Errorf("expected P7 violation error, got: %v", vr.Errors)
	}
}

func TestValidateMeasureOutput_P7NoViolation(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Good naming task",
		Description: `deliverable_type: code
files:
  - path: pkg/difftest/runner.go
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
	}}

	// runner.go in pkg/difftest/ is NOT a P7 violation because
	// the file name does not match the parent directory name.
	vr := validateMeasureOutput(issues, 0)
	p7Errors := 0
	for _, e := range vr.Errors {
		if contains(e, "P7 violation") {
			p7Errors++
		}
	}
	if p7Errors > 0 {
		t.Errorf("expected no P7 violation for difftest/runner.go, got %d: %v", p7Errors, vr.Errors)
	}
}

func TestValidateMeasureOutput_UnparseableDescription(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{{
		Index: 0,
		Title: "Bad YAML task",
		Description: `{{{not valid yaml`,
	}}

	vr := validateMeasureOutput(issues, 0)
	if len(vr.Warnings) == 0 {
		t.Error("expected warning for unparseable description")
	}
}

func TestValidateMeasureOutput_MultipleIssues(t *testing.T) {
	t.Parallel()
	issues := []proposedIssue{
		{
			Index: 0,
			Title: "Valid task",
			Description: `deliverable_type: code
requirements:
  - id: R1
    text: req1
  - id: R2
    text: req2
  - id: R3
    text: req3
  - id: R4
    text: req4
  - id: R5
    text: req5
acceptance_criteria:
  - id: AC1
    text: ac1
  - id: AC2
    text: ac2
  - id: AC3
    text: ac3
  - id: AC4
    text: ac4
  - id: AC5
    text: ac5
design_decisions:
  - id: D1
    text: d1
  - id: D2
    text: d2
  - id: D3
    text: d3
`,
		},
		{
			Index: 1,
			Title: "Invalid task",
			Description: `deliverable_type: code
requirements:
  - id: R1
    text: req1
acceptance_criteria:
  - id: AC1
    text: ac1
`,
		},
	}

	vr := validateMeasureOutput(issues, 0)
	if !vr.HasErrors() {
		t.Error("expected errors from invalid second issue")
	}
}

func TestValidationResult_HasErrors(t *testing.T) {
	t.Parallel()

	empty := validationResult{}
	if empty.HasErrors() {
		t.Error("empty result should not have errors")
	}

	warningsOnly := validationResult{Warnings: []string{"warn"}}
	if warningsOnly.HasErrors() {
		t.Error("warnings-only result should not have errors")
	}

	withErrors := validationResult{Errors: []string{"err"}}
	if !withErrors.HasErrors() {
		t.Error("result with errors should have errors")
	}
}

// --- parseCompletedWork ---

func TestParseCompletedWork_ValidJSON(t *testing.T) {
	t.Parallel()
	input := `[
		{"id": "abc-123", "title": "Implement feature X", "status": "closed", "type": "task"},
		{"id": "abc-124", "title": "Add tests for X", "status": "closed", "type": "task"}
	]`
	got := parseCompletedWork([]byte(input))
	if len(got) != 2 {
		t.Fatalf("got %d summaries, want 2", len(got))
	}
	if got[0] != "COMPLETED: abc-123 — Implement feature X" {
		t.Errorf("got[0] = %q, want COMPLETED prefix with id and title", got[0])
	}
	if got[1] != "COMPLETED: abc-124 — Add tests for X" {
		t.Errorf("got[1] = %q, want COMPLETED prefix with id and title", got[1])
	}
}

func TestParseCompletedWork_EmptyArray(t *testing.T) {
	t.Parallel()
	got := parseCompletedWork([]byte("[]"))
	if len(got) != 0 {
		t.Errorf("got %d summaries, want 0", len(got))
	}
}

func TestParseCompletedWork_InvalidJSON(t *testing.T) {
	t.Parallel()
	got := parseCompletedWork([]byte("{not json"))
	if got != nil {
		t.Errorf("got %v, want nil for invalid JSON", got)
	}
}

// --- MaxRequirementsPerTask limit ---

func TestValidateMeasureOutput_MaxReqs_ZeroIsUnlimited(t *testing.T) {
	t.Parallel()
	// maxReqs=0 must never trigger an error, even with 10 requirements.
	var reqs string
	for i := 1; i <= 10; i++ {
		reqs += "  - id: R" + fmt.Sprintf("%d", i) + "\n    text: req\n"
	}
	issues := []proposedIssue{{
		Index:       0,
		Title:       "Huge task",
		Description: "deliverable_type: code\nrequirements:\n" + reqs,
	}}
	vr := validateMeasureOutput(issues, 0)
	for _, e := range vr.Errors {
		if contains(e, "max is") {
			t.Errorf("maxReqs=0 should not produce max-requirements error, got: %s", e)
		}
	}
}

func TestValidateMeasureOutput_MaxReqs_ExactlyAtLimit_NoError(t *testing.T) {
	t.Parallel()
	// 5 requirements with maxReqs=5 must not trigger the limit error.
	issues := []proposedIssue{{
		Index: 0,
		Title: "At-limit task",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req
  - id: R2
    text: req
  - id: R3
    text: req
  - id: R4
    text: req
  - id: R5
    text: req
`,
	}}
	vr := validateMeasureOutput(issues, 5)
	for _, e := range vr.Errors {
		if contains(e, "max is") {
			t.Errorf("5 requirements at maxReqs=5 should not error, got: %s", e)
		}
	}
}

func TestValidateMeasureOutput_MaxReqs_ExceedsLimit_Error(t *testing.T) {
	t.Parallel()
	// 6 requirements with maxReqs=5 must produce a max-requirements error.
	issues := []proposedIssue{{
		Index: 0,
		Title: "Oversized task",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req
  - id: R2
    text: req
  - id: R3
    text: req
  - id: R4
    text: req
  - id: R5
    text: req
  - id: R6
    text: req
`,
	}}
	vr := validateMeasureOutput(issues, 5)
	found := false
	for _, e := range vr.Errors {
		if contains(e, "max is") {
			found = true
			break
		}
	}
	if !found {
		t.Errorf("expected max-requirements error for 6 reqs with limit 5, got errors: %v", vr.Errors)
	}
}

func TestValidateMeasureOutput_MaxReqs_ErrorMentionsCountAndLimit(t *testing.T) {
	t.Parallel()
	// Error message must include both the actual count and the configured limit.
	issues := []proposedIssue{{
		Index: 1,
		Title: "Task Title",
		Description: `deliverable_type: code
requirements:
  - id: R1
    text: req
  - id: R2
    text: req
  - id: R3
    text: req
  - id: R4
    text: req
  - id: R5
    text: req
  - id: R6
    text: req
  - id: R7
    text: req
  - id: R8
    text: req
`,
	}}
	vr := validateMeasureOutput(issues, 5)
	found := false
	for _, e := range vr.Errors {
		if contains(e, "8") && contains(e, "5") && contains(e, "Task Title") {
			found = true
			break
		}
	}
	if !found {
		t.Errorf("error should mention count (8), limit (5), and title; got: %v", vr.Errors)
	}
}

func TestParseCompletedWork_NilInput(t *testing.T) {
	t.Parallel()
	got := parseCompletedWork(nil)
	if got != nil {
		t.Errorf("got %v, want nil for nil input", got)
	}
}

// contains checks if substr is in s. Avoids importing strings in test.
func contains(s, substr string) bool {
	for i := 0; i+len(substr) <= len(s); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}
